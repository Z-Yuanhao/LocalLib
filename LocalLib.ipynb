{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for Dev purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "#Manage Imports\n",
    "\n",
    "#llamaindex stuff\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    Document,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    SummaryIndex,\n",
    ")\n",
    "from llama_index.llms.groq import Groq\n",
    "#Document Readers\n",
    "import ebooklib\n",
    "from bs4 import BeautifulSoup\n",
    "from ebooklib import epub\n",
    "\n",
    "#Initalize LLM and Embedding Model\n",
    "\n",
    "#Using Groq Temporarily due to low computer ram.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = Groq(model=\"llama3-groq-70b-8192-tool-use-preview\", api_key=(os.getenv(\"GROQ_API_KEY\")))\n",
    "#llm = Ollama(model=\"llama3.2:latest\", temperature=0)\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "#Settings the models to be used\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "#Settings for the chunk size and overlap for efficient embedding at VectorStoreIndex\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 30\n",
    "\n",
    "\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Document Object through SimpleDirectoryReader.\n",
      "Loaded Document of Title : Chapter5.4_Covariance.pdf\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Document Processing\n",
    "file_name = input(\" Enter the (enter) file name inside the document directory: \")\n",
    "document = 'documents/' + file_name\n",
    "\n",
    "#Ebooks(Text)\n",
    "\n",
    "if file_name.lower().endswith('.epub'):\n",
    "    if debug:\n",
    "        print(\"Loading Ebook through Epub Reader.\")\n",
    "    book = epub.read_epub(document)\n",
    "    #Initialize list to store all the text\n",
    "    all_text = []\n",
    "    if debug and book.get_metadata('DC', 'title'):\n",
    "        print(f\"Loaded Ebook of Title : {book.get_metadata('DC', 'title')[0][0]}\\n\\n\")\n",
    "    else: \n",
    "        print(\"Loading Unssuccessful\\n\\n\")\n",
    "\n",
    "    for item in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):\n",
    "        #Parse it with soup\n",
    "        soup = BeautifulSoup(item.get_content(), 'html.parser')\n",
    "        text = soup.get_text()\n",
    "\n",
    "        all_text.append(text)\n",
    "    \n",
    "    #Creating Document Object so it can be embedded\n",
    "    full_text = [Document(text=t) for t in all_text]\n",
    "    if debug and full_text:\n",
    "        print(\"Converted Document Object\\n\\n\")\n",
    "    else: \n",
    "        print(\"Convertion Unssuccessful\\n\\n\")\n",
    "\n",
    "#More efficient document parsing modules can be added in the future\n",
    "\n",
    "#General Document Loading\n",
    "else:\n",
    "    if debug:\n",
    "        print('Loading Document Object through SimpleDirectoryReader.')\n",
    "    full_text = SimpleDirectoryReader(input_files=[document]).load_data()\n",
    "    if debug and full_text[0].metadata:\n",
    "        print(f\"Loaded Document of Title : {full_text[0].metadata['file_name']}\\n\\n\")\n",
    "    else: \n",
    "        print(\"Loading Unssuccessful\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#Embedding the Document\n",
    "vector_index = VectorStoreIndex.from_documents(full_text)\n",
    "#for summary purpose\n",
    "summary_index = SummaryIndex.from_documents(full_text)\n",
    "\n",
    "#Define Query Engines to be used(k = 3 for keeping some additional context)\n",
    "vector_query_engine = vector_index.as_query_engine()\n",
    "summary_query_engine = summary_index.as_query_engine()\n",
    "\n",
    "# define tools\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=vector_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"vector_tool\",\n",
    "            description=(\n",
    "                f\"Useful for retrieving specific context from {file_name}\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=summary_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"summary_tool\",\n",
    "            description=(\n",
    "                f\"Useful for summarization questions related to {file_name}\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "#Build document specific agent\n",
    "if debug:\n",
    "    agent = ReActAgent.from_tools(\n",
    "        query_engine_tools,\n",
    "        llm = llm,\n",
    "        verbose=True,\n",
    "    )\n",
    "else:\n",
    "    agent = ReActAgent.from_tools(\n",
    "        query_engine_tools,\n",
    "        llm = llm,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "#Index nodes for future multi-doc module\n",
    "objects = []\n",
    "\n",
    "file_summary = (\n",
    "    \"Use this index if you need to lookup specific facts about\"\n",
    "    f\" {file_name}.\"\n",
    ")\n",
    "\n",
    "node = IndexNode(\n",
    "    text=file_summary, index_id=file_name, obj=agent\n",
    ")\n",
    "objects.append(node)\n",
    "\n",
    "\n",
    "#Query Engine\n",
    "vector_index = VectorStoreIndex(\n",
    "    objects=objects,\n",
    ")\n",
    "\n",
    "if debug:\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=1, verbose=True)\n",
    "else:\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for print\n",
    "def print_response(response):\n",
    "    display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203mRetrieval entering Chapter5.4_Covariance.pdf: ReActAgent\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object ReActAgent with query summarize the first three aspects covered in the document\n",
      "\u001b[0m> Running step 4dfa6459-5abb-49df-b917-ea46ee95754c. Step input: summarize the first three aspects covered in the document\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: summary_tool\n",
      "Action Input: {'input': 'summarize the first three aspects covered in the document'}\n",
      "\u001b[0mHTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;34mObservation: The first three aspects covered in the document are:\n",
      "\n",
      "1. Introduction to Covariance: The document introduces the concept of covariance, which measures the linear relationship between two random variables, X and Y. It explains that a positive covariance indicates that X and Y tend to increase or decrease together, while a negative covariance implies that an increase in X typically leads to a decrease in Y.\n",
      "\n",
      "2. Understanding the Sign of Covariance: The document explains that covariance depends on the scale of X and Y, and that scaling one variable affects the covariance. It also highlights that covariance can be negative, indicating a negative linear relationship between the variables.\n",
      "\n",
      "3. Definition of Pearson Correlation: The document defines Pearson correlation as a normalized version of covariance that measures the strength and direction of the linear relationship between two variables. It also discusses the properties of correlation, including the range of -1 to 1, and the fact that a correlation of ±1 indicates a perfect linear relationship.\n",
      "\u001b[0m> Running step 8ecfa422-1b18-45b0-a5e7-15143bb77b9b. Step input: None\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: Answer: The first three aspects covered in the document are: 1) Introduction to Covariance, which explains the concept of covariance and its relationship with random variables; 2) Understanding the Sign of Covariance, which discusses how scaling affects covariance and the possibility of a negative covariance; and 3) Definition of Pearson Correlation, which defines correlation as a normalized version of covariance and discusses its properties.\n",
      "\u001b[0mHTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px\">The first three aspects covered in the document are: 1) Introduction to Covariance, which explains the concept of covariance and its relationship with random variables; 2) Understanding the Sign of Covariance, which discusses how scaling affects covariance and the possibility of a negative covariance; and 3) Definition of Pearson Correlation, which defines correlation as a normalized version of covariance and discusses its properties.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"summarize the first three aspects covered in the document\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
